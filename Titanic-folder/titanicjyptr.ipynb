{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86eb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.0 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.9/11.0 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.8 MB 14.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.8 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.4 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Requirement already satisfied: pandas in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (2.3.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kyleo\\.julia\\conda\\3\\x86_64\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.1/8.7 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.7/8.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.9/8.1 MB 15.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Downloading pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 3.1/7.0 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.0/7.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 13.5 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.9/38.6 MB 13.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.0/38.6 MB 14.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.4/38.6 MB 14.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.3/38.6 MB 14.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 15.5/38.6 MB 14.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.1/38.6 MB 14.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.0/38.6 MB 14.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.9/38.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.0/38.6 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.5/38.6 MB 14.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/38.6 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 14.2 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
      "\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   ------- --------------------------------  2/11 [pyparsing]\n",
      "   ---------- -----------------------------  3/11 [pillow]\n",
      "   ---------- -----------------------------  3/11 [pillow]\n",
      "   ---------- -----------------------------  3/11 [pillow]\n",
      "   ---------- -----------------------------  3/11 [pillow]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   --------------------- ------------------  6/11 [fonttools]\n",
      "   ----------------------------- ----------  8/11 [contourpy]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   -------------------------------- -------  9/11 [scikit-learn]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [matplotlib]\n",
      "   ---------------------------------------- 11/11 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.7 pillow-12.0.0 pyparsing-3.2.5 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "480dae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "traindf=pd.read_csv('train.csv')\n",
    "testdf=pd.read_csv('test.csv')\n",
    "traindf[\"Title\"] = traindf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "testdf[\"Title\"] = testdf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, np.inf]\n",
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "traindf['AgeRange'] = pd.cut(traindf['Age'], bins=bins, labels=labels, right=False)\n",
    "testdf['AgeRange'] = pd.cut(traindf['Age'], bins=bins, labels=labels, right=False)\n",
    "testdf[\"CabinLetter\"] = testdf['Cabin'].str[0]\n",
    "traindf[\"CabinLetter\"] = traindf['Cabin'].str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "820f90c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test df missing data counts:\n",
      "# of entries with empty Pclass: 0\n",
      "# of entries with empty Name: 0\n",
      "# of entries with empty Sex: 0\n",
      "# of entries with empty Age: 86\n",
      "# of entries with empty SibSp: 0\n",
      "# of entries with empty Parch: 0\n",
      "# of entries with empty Ticket: 0\n",
      "# of entries with empty Fare: 1\n",
      "# of entries with empty Cabin: 327\n",
      "# of entries with empty Embarked: 0\n",
      "Train df missing data counts:\n",
      "# of entries with empty Pclass: 0\n",
      "# of entries with empty Name: 0\n",
      "# of entries with empty Sex: 0\n",
      "# of entries with empty Age: 177\n",
      "# of entries with empty SibSp: 0\n",
      "# of entries with empty Parch: 0\n",
      "# of entries with empty Ticket: 0\n",
      "# of entries with empty Fare: 0\n",
      "# of entries with empty Cabin: 687\n",
      "# of entries with empty Embarked: 2\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('test.csv')\n",
    "traindf = pd.read_csv('train.csv')\n",
    "\n",
    "print(\"Test df missing data counts:\")\n",
    "\n",
    "embarkedClassCount = testdf[\"Pclass\"].isnull().sum()\n",
    "print(f'# of entries with empty Pclass: {embarkedClassCount}')\n",
    "\n",
    "embarkedNameCount = testdf[\"Name\"].isnull().sum()\n",
    "print(f'# of entries with empty Name: {embarkedNameCount}')\n",
    "\n",
    "embarkedSexCount = testdf[\"Sex\"].isnull().sum()\n",
    "print(f'# of entries with empty Sex: {embarkedSexCount}')\n",
    "\n",
    "embarkedAgeCount = testdf[\"Age\"].isnull().sum()\n",
    "print(f'# of entries with empty Age: {embarkedAgeCount}')\n",
    "\n",
    "embarkedSibSpCount = testdf[\"SibSp\"].isnull().sum()\n",
    "print(f'# of entries with empty SibSp: {embarkedSibSpCount}')\n",
    "\n",
    "embarkedParchCount = testdf[\"Parch\"].isnull().sum()\n",
    "print(f'# of entries with empty Parch: {embarkedParchCount}')\n",
    "\n",
    "embarkedTicketCount = testdf[\"Ticket\"].isnull().sum()\n",
    "print(f'# of entries with empty Ticket: {embarkedTicketCount}')\n",
    "\n",
    "embarkedFareCount = testdf[\"Fare\"].isnull().sum()\n",
    "print(f'# of entries with empty Fare: {embarkedFareCount}')\n",
    "\n",
    "embarkedCabinCount = testdf[\"Cabin\"].isnull().sum()\n",
    "print(f'# of entries with empty Cabin: {embarkedCabinCount}')\n",
    "\n",
    "embarkedEmptyCount = testdf[\"Embarked\"].isnull().sum()\n",
    "print(f'# of entries with empty Embarked: {embarkedEmptyCount}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train df missing data counts:\")\n",
    "\n",
    "embarkedClassCount = traindf[\"Pclass\"].isnull().sum()\n",
    "print(f'# of entries with empty Pclass: {embarkedClassCount}')\n",
    "\n",
    "embarkedNameCount = traindf[\"Name\"].isnull().sum()\n",
    "print(f'# of entries with empty Name: {embarkedNameCount}')\n",
    "\n",
    "embarkedSexCount = traindf[\"Sex\"].isnull().sum()\n",
    "print(f'# of entries with empty Sex: {embarkedSexCount}')\n",
    "\n",
    "embarkedAgeCount = traindf[\"Age\"].isnull().sum()\n",
    "print(f'# of entries with empty Age: {embarkedAgeCount}')\n",
    "\n",
    "embarkedSibSpCount = traindf[\"SibSp\"].isnull().sum()\n",
    "print(f'# of entries with empty SibSp: {embarkedSibSpCount}')\n",
    "\n",
    "embarkedParchCount = traindf[\"Parch\"].isnull().sum()\n",
    "print(f'# of entries with empty Parch: {embarkedParchCount}')\n",
    "\n",
    "embarkedTicketCount = traindf[\"Ticket\"].isnull().sum()\n",
    "print(f'# of entries with empty Ticket: {embarkedTicketCount}')\n",
    "\n",
    "embarkedFareCount = traindf[\"Fare\"].isnull().sum()\n",
    "print(f'# of entries with empty Fare: {embarkedFareCount}')\n",
    "\n",
    "embarkedCabinCount = traindf[\"Cabin\"].isnull().sum()\n",
    "print(f'# of entries with empty Cabin: {embarkedCabinCount}')\n",
    "\n",
    "embarkedEmptyCount = traindf[\"Embarked\"].isnull().sum()\n",
    "print(f'# of entries with empty Embarked: {embarkedEmptyCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f130b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival counts by class:\n",
      "Survived    0    1\n",
      "Pclass            \n",
      "1          80  136\n",
      "2          97   87\n",
      "3         372  119\n",
      "\n",
      "Survival counts by title:\n",
      "Survived    0    1\n",
      "Title             \n",
      "Capt        1    0\n",
      "Col         1    1\n",
      "Don         1    0\n",
      "Dr          4    3\n",
      "Jonkheer    1    0\n",
      "Lady        0    1\n",
      "Major       1    1\n",
      "Master     17   23\n",
      "Miss       55  127\n",
      "Mlle        0    2\n",
      "Mme         0    1\n",
      "Mr        436   81\n",
      "Mrs        26   99\n",
      "Ms          0    1\n",
      "Rev         6    0\n",
      "Sir         0    1\n",
      "\n",
      "Survival counts by sex:\n",
      "Survived    0    1\n",
      "Sex               \n",
      "female     81  233\n",
      "male      468  109\n",
      "\n",
      "Survival counts by sibsp:\n",
      "Survived    0    1\n",
      "SibSp             \n",
      "0         398  210\n",
      "1          97  112\n",
      "2          15   13\n",
      "3          12    4\n",
      "4          15    3\n",
      "5           5    0\n",
      "8           7    0\n",
      "\n",
      "Survival counts by parch:\n",
      "Survived    0    1\n",
      "Parch             \n",
      "0         445  233\n",
      "1          53   65\n",
      "2          40   40\n",
      "3           2    3\n",
      "4           4    0\n",
      "5           4    1\n",
      "6           1    0\n",
      "\n",
      "Survival counts by embarked port:\n",
      "Survived    0    1\n",
      "Embarked          \n",
      "C          75   93\n",
      "Q          47   30\n",
      "S         427  217\n",
      "\n",
      "Survival counts by cabin letter:\n",
      "Survived       0    1\n",
      "CabinLetter          \n",
      "A              8    7\n",
      "B             12   35\n",
      "C             24   35\n",
      "D              8   25\n",
      "E              8   24\n",
      "F              5    8\n",
      "G              2    2\n",
      "N            481  206\n",
      "T              1    0\n",
      "\n",
      "Survival counts by age range:\n",
      "Survived    0   1\n",
      "AgeRange         \n",
      "0-9        24  38\n",
      "10-19      61  41\n",
      "20-29     143  77\n",
      "30-39      94  73\n",
      "40-49      55  34\n",
      "50-59      28  20\n",
      "60-69      13   6\n",
      "70+         6   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_survival_counts = pd.crosstab(traindf['Pclass'], traindf['Survived'])\n",
    "print(\"Survival counts by class:\")\n",
    "print(class_survival_counts)\n",
    "print()\n",
    "\n",
    "title_survival_counts = pd.crosstab(traindf['Title'], traindf['Survived'])\n",
    "print(\"Survival counts by title:\")\n",
    "print(title_survival_counts)\n",
    "print()\n",
    "\n",
    "sex_survival_counts = pd.crosstab(traindf['Sex'], traindf['Survived'])\n",
    "print(\"Survival counts by sex:\")\n",
    "print(sex_survival_counts)\n",
    "print()\n",
    "\n",
    "sibsp_survival_counts = pd.crosstab(traindf['SibSp'], traindf['Survived'])\n",
    "print(\"Survival counts by sibsp:\")\n",
    "print(sibsp_survival_counts)\n",
    "print()\n",
    "\n",
    "parch_survival_counts = pd.crosstab(traindf['Parch'], traindf['Survived'])\n",
    "print(\"Survival counts by parch:\")\n",
    "print(parch_survival_counts)\n",
    "print()\n",
    "\n",
    "embarked_survival_counts = pd.crosstab(traindf['Embarked'], traindf['Survived'])\n",
    "print(\"Survival counts by embarked port:\")\n",
    "print(embarked_survival_counts)\n",
    "print()\n",
    "\n",
    "traindf[\"CabinLetter\"] = traindf[\"CabinLetter\"].fillna(\"N\")\n",
    "\n",
    "cabin_letter_survival_counts = pd.crosstab(traindf['CabinLetter'], traindf['Survived'])\n",
    "print(\"Survival counts by cabin letter:\")\n",
    "print(cabin_letter_survival_counts)\n",
    "print()\n",
    "\n",
    "age_range_survival_counts = pd.crosstab(traindf['AgeRange'], traindf['Survived'])\n",
    "print(\"Survival counts by age range:\")\n",
    "print(age_range_survival_counts)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeRange  0-9  10-19  20-29  30-39  40-49  50-59  60-69  70+\n",
      "Pclass                                                      \n",
      "1           3     18     34     50     37     27     13    4\n",
      "2          17     18     53     48     18     15      3    1\n",
      "3          42     66    133     69     34      6      3    2\n",
      "\n",
      "\n",
      "AgeRange  0-9  10-19  20-29  30-39  40-49  50-59  60-69  70+\n",
      "Title                                                       \n",
      "Capt        0      0      0      0      0      0      0    1\n",
      "Col         0      0      0      0      0      1      1    0\n",
      "Don         0      0      0      0      1      0      0    0\n",
      "Dr          0      0      1      1      2      2      0    0\n",
      "Jonkheer    0      0      0      1      0      0      0    0\n",
      "Lady        0      0      0      0      1      0      0    0\n",
      "Major       0      0      0      0      1      1      0    0\n",
      "Master     32      4      0      0      0      0      0    0\n",
      "Miss       30     36     40     28      5      6      1    0\n",
      "Mlle        0      0      2      0      0      0      0    0\n",
      "Mme         0      0      1      0      0      0      0    0\n",
      "Mr          0     53    145    105     52     23     14    6\n",
      "Mrs         0      9     28     31     25     12      3    0\n",
      "Ms          0      0      1      0      0      0      0    0\n",
      "Rev         0      0      2      0      1      3      0    0\n",
      "Sir         0      0      0      0      1      0      0    0\n",
      "\n",
      "\n",
      "Title\n",
      "Mr        119\n",
      "Miss       36\n",
      "Mrs        17\n",
      "Master      4\n",
      "Dr          1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint()\\n\\nembarked_class_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"Pclass\"])\\nprint(embarked_class_counts)\\n\\nprint()\\n\\nembarkedEmptyPclass3Count = (traindf[\"Embarked\"].isnull() & (traindf[\"Pclass\"] == 3)).sum()\\nprint(f\\'# of entries with empty Embarked and Pclass 3: {embarkedEmptyPclass3Count}\\')\\n\\ntraindf.loc[(traindf[\"Embarked\"].isnull()) & (traindf[\"Pclass\"] == 3), \"Embarked\"] = \\'Q\\'\\n\\nprint(traindf[\"Embarked\"].isnull().sum())\\n\\ntraindf[\"CabinLetter\"] = traindf[\\'Cabin\\'].str[0]\\nembarked_cabin_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"CabinLetter\"])\\nprint(embarked_cabin_counts)\\n\\nprint()\\n\\nembarked_fare_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"Fare\"])\\nprint(embarked_fare_counts)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#age_survival_counts = pd.crosstab(traindf[\"Age\"], traindf[\"Survived\"])\n",
    "#print(age_survival_counts)\n",
    "\n",
    "\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, np.inf]\n",
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "\n",
    "\n",
    "age_range_class_counts = pd.crosstab(traindf['Pclass'], traindf['AgeRange'])\n",
    "print(age_range_class_counts)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "traindf[\"Title\"] = traindf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "age_range_title_counts = pd.crosstab(traindf[\"Title\"], traindf[\"AgeRange\"])\n",
    "print(age_range_title_counts)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print()\n",
    "\n",
    "embarked_class_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"Pclass\"])\n",
    "print(embarked_class_counts)\n",
    "\n",
    "print()\n",
    "\n",
    "embarkedEmptyPclass3Count = (traindf[\"Embarked\"].isnull() & (traindf[\"Pclass\"] == 3)).sum()\n",
    "print(f'# of entries with empty Embarked and Pclass 3: {embarkedEmptyPclass3Count}')\n",
    "\n",
    "traindf.loc[(traindf[\"Embarked\"].isnull()) & (traindf[\"Pclass\"] == 3), \"Embarked\"] = 'Q'\n",
    "\n",
    "print(traindf[\"Embarked\"].isnull().sum())\n",
    "\n",
    "traindf[\"CabinLetter\"] = traindf['Cabin'].str[0]\n",
    "embarked_cabin_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"CabinLetter\"])\n",
    "print(embarked_cabin_counts)\n",
    "\n",
    "print()\n",
    "\n",
    "embarked_fare_counts = pd.crosstab(traindf[\"Embarked\"], traindf[\"Fare\"])\n",
    "print(embarked_fare_counts)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b3d9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Mr        119\n",
      "Miss       36\n",
      "Mrs        17\n",
      "Master      4\n",
      "Dr          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "traindf[\"Title\"] = traindf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "titleCounts = traindf[traindf['Age'].isnull()]['Title'].value_counts()\n",
    "print(titleCounts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8886fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_Xy():\n",
    "    traindf = pd.read_csv('train.csv')\n",
    "    \n",
    "    traindf[\"Title\"] = traindf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    traindf['Title'] = traindf['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    traindf['Title'] = traindf['Title'].replace('Mlle', 'Miss')\n",
    "    traindf['Title'] = traindf['Title'].replace('Ms', 'Miss')\n",
    "    traindf['Title'] = traindf['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    traindf['Age'] = traindf['Age'].fillna(traindf.groupby('Title')['Age'].transform('mean'))\n",
    "    traindf['Age'] = traindf['Age'].fillna(traindf['Age'].mean()) \n",
    "\n",
    "    mode_embarked = traindf['Embarked'].mode()[0]\n",
    "    traindf['Embarked'] = traindf['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "    traindf['CabinLetter'] = traindf['Cabin'].str[0]\n",
    "    traindf['CabinLetter'] = traindf['CabinLetter'].fillna(\"N\")\n",
    "\n",
    "    traindf['FamilySize'] = traindf['SibSp'] + traindf['Parch'] + 1\n",
    "    traindf['IsAlone'] = (traindf['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    sex_map = {\"male\": 0, \"female\": 1}\n",
    "    traindf['Sex'] = traindf['Sex'].map(sex_map)\n",
    "\n",
    "    traindf['Fare'] = traindf['Fare'].fillna(traindf['Fare'].median())\n",
    "    \n",
    "    features = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone',\n",
    "                'Embarked', 'Title', 'CabinLetter']\n",
    "    \n",
    "    y = traindf['Survived']\n",
    "    X = traindf[features] \n",
    "    \n",
    "    X_processed = pd.get_dummies(X, columns=['Embarked', 'Title', 'CabinLetter'], drop_first=True)\n",
    "    \n",
    "    return (X_processed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4041a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_X():\n",
    "    testdf = pd.read_csv('test.csv')\n",
    "    \n",
    "    testdf[\"Title\"] = testdf['Name'].str.extract(r', ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    testdf['Title'] = testdf['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    testdf['Title'] = testdf['Title'].replace('Mlle', 'Miss')\n",
    "    testdf['Title'] = testdf['Title'].replace('Ms', 'Miss')\n",
    "    testdf['Title'] = testdf['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    testdf['Age'] = testdf['Age'].fillna(testdf.groupby('Title')['Age'].transform('mean'))\n",
    "    testdf['Age'] = testdf['Age'].fillna(testdf['Age'].mean()) \n",
    "\n",
    "    mode_embarked = testdf['Embarked'].mode()[0]\n",
    "    testdf['Embarked'] = testdf['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "    testdf['CabinLetter'] = testdf['Cabin'].str[0]\n",
    "    testdf['CabinLetter'] = testdf['CabinLetter'].fillna(\"N\")\n",
    "\n",
    "    testdf['FamilySize'] = testdf['SibSp'] + testdf['Parch'] + 1\n",
    "    testdf['IsAlone'] = (testdf['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    sex_map = {\"male\": 0, \"female\": 1}\n",
    "    testdf['Sex'] = testdf['Sex'].map(sex_map)\n",
    "\n",
    "    testdf['Fare'] = testdf['Fare'].fillna(testdf['Fare'].median())\n",
    "    \n",
    "    features = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone',\n",
    "                'Embarked', 'Title', 'CabinLetter']\n",
    "    \n",
    "    X = testdf[features] \n",
    "    \n",
    "    X_processed = pd.get_dummies(X, columns=['Embarked', 'Title', 'CabinLetter'], drop_first=True)\n",
    "    \n",
    "    return (X_processed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e2b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'min_sample_leaves'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrandom forest test MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, mse\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m random_forest_test(\u001b[32m42\u001b[39m, \u001b[32m115\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m15\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrandom_forest_test\u001b[39m\u001b[34m(seed, n_estimators, num_leaves, max_depth)\u001b[39m\n\u001b[32m      2\u001b[39m X, y = get_filtered_Xy()\n\u001b[32m      4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=seed)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m clf = RandomForestClassifier(n_estimators=n_estimators, min_sample_leaves =num_leaves, max_depth=max_depth, random_state=seed)\n\u001b[32m      7\u001b[39m clf.fit(X_train, y_train)\n\u001b[32m      9\u001b[39m accuracy = clf.score(X_test, y_test)\n",
      "\u001b[31mTypeError\u001b[39m: RandomForestClassifier.__init__() got an unexpected keyword argument 'min_sample_leaves'"
     ]
    }
   ],
   "source": [
    "def random_forest_test(seed, n_estimators, num_leaves, max_depth):\n",
    "    X, y = get_filtered_Xy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, min_sample_leaves =num_leaves, max_depth=max_depth, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    mse = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    print(f\"random forest test accurancy: {accuracy}\")\n",
    "    print(f\"random forest test MSE: {mse}\")\n",
    "    return accuracy, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2316ba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Grid search finished!\n",
      "Best parameters found: {'max_depth': 15, 'min_samples_leaf': 3, 'n_estimators': 115}\n",
      "Best cross-validation accuracy: 0.8399\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "X, y = get_filtered_Xy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [110, 115, 120],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'max_depth': [None, 12, 15, 18]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,   \n",
    "    cv=5,                     \n",
    "    scoring='accuracy',       \n",
    "    n_jobs=-1,                 \n",
    "    verbose=2                  \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Starting grid search...\")\n",
    "grid_search.fit(X_train, y_train) \n",
    "print(\"Grid search finished!\")\n",
    "\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c05599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission():\n",
    "    model = RandomForestClassifier(n_estimators=115, max_depth=15, min_samples_leaf=3)\n",
    "    X_train, y_train = get_filtered_Xy()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = get_filtered_X()\n",
    "    predicitions = model.predict(X_test)\n",
    "\n",
    "    submission_df = pd.read_csv('test.csv')\n",
    "    submission_df['Survived'] = predicitions\n",
    "    submission_df = submission_df[['PassengerId', 'Survived']]\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e24fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
